{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voice AI Data Analysis Demo\n",
    "\n",
    "This notebook demonstrates how to connect to and analyze data from the Voice AI Agent.\n",
    "\n",
    "## What you'll learn:\n",
    "- How to connect to PostgreSQL and Redis\n",
    "- How to query conversation data\n",
    "- How to visualize session statistics\n",
    "- How to test API endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "# Setup: Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sqlalchemy import create_engine\n",
    "import redis\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Set visualization style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"âœ“ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Check\n",
    "\n",
    "Let's verify we can access the necessary services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection Configuration:\n",
      "Database: postgresql://voiceai:voiceai_dev@localhost:5432/voiceai_db\n",
      "Redis: redis://localhost:6379\n",
      "API: http://localhost:8000\n"
     ]
    }
   ],
   "source": [
    "# Connection strings for local access to Docker services\n",
    "DATABASE_URL = 'postgresql://voiceai:voiceai_dev@localhost:5432/voiceai_db'\n",
    "REDIS_URL = 'redis://localhost:6379'\n",
    "API_BASE_URL = 'http://localhost:8000'\n",
    "\n",
    "print(\"Connection Configuration:\")\n",
    "print(f\"Database: {DATABASE_URL}\")\n",
    "print(f\"Redis: {REDIS_URL}\")\n",
    "print(f\"API: {API_BASE_URL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Database Connection Test\n",
    "\n",
    "Verify we can connect to PostgreSQL and query conversation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ— Database error: (psycopg2.errors.UndefinedTable) relation \"conversations.conversation_sessions\" does not exist\n",
      "LINE 8: FROM conversations.conversation_sessions\n",
      "             ^\n",
      "\n",
      "[SQL: \n",
      "SELECT \n",
      "    session_id,\n",
      "    session_type,\n",
      "    direction,\n",
      "    status,\n",
      "    created_at\n",
      "FROM conversations.conversation_sessions\n",
      "ORDER BY created_at DESC\n",
      "LIMIT 10;\n",
      "]\n",
      "(Background on this error at: https://sqlalche.me/e/20/f405)\n",
      "\n",
      "Make sure Docker services are running: make dev\n"
     ]
    }
   ],
   "source": [
    "# Create database connection\n",
    "engine = create_engine(DATABASE_URL)\n",
    "\n",
    "# Test query: Get recent conversation sessions\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    session_id,\n",
    "    session_type,\n",
    "    direction,\n",
    "    status,\n",
    "    created_at\n",
    "FROM conversations.conversation_sessions\n",
    "ORDER BY created_at DESC\n",
    "LIMIT 10;\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    df = pd.read_sql(query, engine)\n",
    "    print(f\"âœ“ Database connection successful\")\n",
    "    print(f\"\\nRecent conversation sessions ({len(df)}):\\n\")\n",
    "    display(df)\n",
    "except Exception as e:\n",
    "    print(f\"âœ— Database error: {e}\")\n",
    "    print(\"\\nMake sure Docker services are running: make dev\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Redis Connection Test\n",
    "\n",
    "Test connection to Redis for session state management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Redis\n",
    "r = redis.from_url(REDIS_URL)\n",
    "\n",
    "try:\n",
    "    # Test connection\n",
    "    r.ping()\n",
    "    print(\"âœ“ Redis connection successful\")\n",
    "    \n",
    "    # Get some stats\n",
    "    info = r.info('stats')\n",
    "    print(f\"\\nRedis Stats:\")\n",
    "    print(f\"  Total connections: {info.get('total_connections_received', 0)}\")\n",
    "    print(f\"  Total commands: {info.get('total_commands_processed', 0)}\")\n",
    "    \n",
    "    # List conversation session keys\n",
    "    session_keys = r.keys('conversation:session:*')\n",
    "    print(f\"\\nActive conversation sessions: {len(session_keys)}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âœ— Redis error: {e}\")\n",
    "    print(\"\\nMake sure Docker services are running: make dev\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. API Health Check\n",
    "\n",
    "Test the API endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    response = requests.get(f'{API_BASE_URL}/api/v1/health', timeout=5)\n",
    "    \n",
    "    if response.ok:\n",
    "        print(\"âœ“ API is healthy\")\n",
    "        print(f\"\\nResponse:\")\n",
    "        print(response.json())\n",
    "    else:\n",
    "        print(f\"âœ— API returned status {response.status_code}\")\n",
    "        \n",
    "except requests.exceptions.ConnectionError:\n",
    "    print(\"âœ— Could not connect to API\")\n",
    "    print(\"\\nMake sure Docker services are running: make dev\")\n",
    "except Exception as e:\n",
    "    print(f\"âœ— Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Session Statistics\n",
    "\n",
    "Analyze conversation session statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get session statistics\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    DATE(created_at) as date,\n",
    "    COUNT(*) as total_sessions,\n",
    "    COUNT(CASE WHEN status = 'completed' THEN 1 END) as completed_sessions,\n",
    "    COUNT(CASE WHEN status = 'active' THEN 1 END) as active_sessions,\n",
    "    COUNT(CASE WHEN direction = 'inbound' THEN 1 END) as inbound_calls,\n",
    "    COUNT(CASE WHEN direction = 'outbound' THEN 1 END) as outbound_calls\n",
    "FROM conversations.conversation_sessions\n",
    "WHERE created_at >= NOW() - INTERVAL '30 days'\n",
    "GROUP BY DATE(created_at)\n",
    "ORDER BY date DESC;\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    df_sessions = pd.read_sql(query, engine)\n",
    "    \n",
    "    if len(df_sessions) > 0:\n",
    "        print(f\"Sessions in last 30 days: {df_sessions['total_sessions'].sum()}\")\n",
    "        display(df_sessions.head(10))\n",
    "        \n",
    "        # Visualize\n",
    "        fig, ax = plt.subplots(figsize=(12, 5))\n",
    "        ax.plot(df_sessions['date'], df_sessions['total_sessions'], marker='o', linewidth=2, label='Total')\n",
    "        ax.plot(df_sessions['date'], df_sessions['completed_sessions'], marker='s', linewidth=2, label='Completed')\n",
    "        ax.set_title('Session Volume Over Time', fontsize=14, fontweight='bold')\n",
    "        ax.set_xlabel('Date')\n",
    "        ax.set_ylabel('Number of Sessions')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"No session data available yet\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error querying sessions: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Test TTS API Endpoint\n",
    "\n",
    "Test the text-to-speech API (optional - requires API to be running)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test TTS endpoint\n",
    "test_text = \"Hello! This is a test of the voice synthesis system.\"\n",
    "\n",
    "try:\n",
    "    response = requests.post(\n",
    "        f'{API_BASE_URL}/api/v1/voice/synthesize',\n",
    "        json={'text': test_text, 'voice_id': 'default'},\n",
    "        timeout=30\n",
    "    )\n",
    "    \n",
    "    if response.ok:\n",
    "        print(f\"âœ“ TTS synthesis successful\")\n",
    "        print(f\"Audio size: {len(response.content)} bytes\")\n",
    "        \n",
    "        # Save audio file\n",
    "        with open('test_tts.wav', 'wb') as f:\n",
    "            f.write(response.content)\n",
    "        print(\"Audio saved to: test_tts.wav\")\n",
    "    else:\n",
    "        print(f\"âœ— TTS failed with status {response.status_code}\")\n",
    "        print(response.text)\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error testing TTS: {e}\")\n",
    "    print(\"This is optional - you can skip if the API isn't fully configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Custom Query Section\n",
    "\n",
    "Use this section for your own custom analysis queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your custom query here\n",
    "custom_query = \"\"\"\n",
    "-- Example: Count sessions by type\n",
    "SELECT \n",
    "    session_type,\n",
    "    COUNT(*) as count\n",
    "FROM conversations.conversation_sessions\n",
    "GROUP BY session_type\n",
    "ORDER BY count DESC;\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    df_custom = pd.read_sql(custom_query, engine)\n",
    "    display(df_custom)\n",
    "except Exception as e:\n",
    "    print(f\"Query error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Explore more notebooks:\n",
    "- `data_analysis/conversation_analytics.ipynb` - Analyze conversation patterns\n",
    "- `model_testing/whisper_testing.ipynb` - Analyze transcription data\n",
    "- `experiments/` - Create your own experiments!\n",
    "\n",
    "Check `notebooks/README.md` for more examples and connection details.\n",
    "\n",
    "Happy analyzing! ðŸš€"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
